{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a8a8998",
   "metadata": {},
   "source": [
    "# ManualAIze development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eebd3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc07ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce1201ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83a50b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Certification - {uuid4().hex[0:8]}\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29522a86",
   "metadata": {},
   "source": [
    "## Let's start building the agent\n",
    "\n",
    "This agent main goal is to parse and retrieve information from user manuals uploaded by the user. The first step will always be retrieval potentially augmented by internet searches. The outile of the agentic loop is the following\n",
    "\n",
    "1. User uploads pdfs \n",
    "2. User inputs a question\n",
    "3. Agent cycle starts\n",
    "    - a. retrieve most relevant information from the uploaded pdfs\n",
    "    - b. router agent evaluates if there is enough context\n",
    "        - i. if not, calls tavily search\n",
    "    - c. once it has enough context calls the writer node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98633170",
   "metadata": {},
   "source": [
    "### Set up the retrieval node\n",
    "Let's start with parsing, embedding and storing the pdfs using Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "916e6d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 PDF files:\n",
      "  - ./data/2024-odyssey.pdf\n",
      "  - ./data/foonf_2024_manual_US_EN_02_27_2024_WEB_Final.pdf\n",
      "  - ./data/2022-mazda-mazda6.pdf\n",
      "\n",
      "Loading ./data/2024-odyssey.pdf...\n",
      "✓ Loaded 702 pages → 1210 chunks in 29.7s\n",
      "\n",
      "Loading ./data/foonf_2024_manual_US_EN_02_27_2024_WEB_Final.pdf...\n",
      "✓ Loaded 100 pages → 143 chunks in 4.0s\n",
      "\n",
      "Loading ./data/2022-mazda-mazda6.pdf...\n",
      "✓ Loaded 702 pages → 1466 chunks in 12.0s\n",
      "\n",
      "Total documents: 2819\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Get all PDF files in the data directory\n",
    "pdf_files = glob.glob(\"./data/*.pdf\")\n",
    "print(f\"Found {len(pdf_files)} PDF files:\")\n",
    "for file in pdf_files:\n",
    "    print(f\"  - {file}\")\n",
    "\n",
    "# Load all PDF files with PyPDF (much faster!)\n",
    "all_documents_pypdf = []\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    try:\n",
    "        print(f\"\\nLoading {pdf_file}...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # PyPDFLoader is MUCH faster than UnstructuredPDFLoader\n",
    "        loader = PyPDFLoader(pdf_file)\n",
    "        pages = loader.load()\n",
    "        \n",
    "        # Split into smaller chunks for better retrieval\n",
    "        documents = text_splitter.split_documents(pages)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        all_documents_pypdf.extend(documents)\n",
    "        print(f\"✓ Loaded {len(pages)} pages → {len(documents)} chunks in {elapsed:.1f}s\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading {pdf_file}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal documents: {len(all_documents_pypdf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30219f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    all_documents_pypdf,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"Manuals\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4061ae",
   "metadata": {},
   "source": [
    "### Now let's create the retrieval node\n",
    "\n",
    "This is not RAG. I want this node to just fetch the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d5893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank\n",
    "\n",
    "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})\n",
    "\n",
    "compressor = CohereRerank(model=\"rerank-v3.5\")\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=naive_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "618e3969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGoAAADqCAIAAADF80cYAAAAAXNSR0IArs4c6QAAFRxJREFUeJztnXtcE1e+wM9k8n6QkBAkECOvYgXBYlB8lAWFKraolbq+29rebq+2az/dfry9fWztVraPz1293e7eravbdre7S6t3a2kVrbbuWkWLFRV8sWoBRSC8AoQkk0wyM5n7R3pZa5NMwkkg0PP9C2bOOfPjy5mZM+fMnIOxLAsQw4U32gGMbZA+KJA+KJA+KJA+KJA+KPiQ+btukISVIQmGdDAMNTbaQLgAE0txsQyXK/EJk8QwRWHDa/ddv0S0XCKaL9gVKn6MWiCW4WIZTyAcG3WZcntIwuMkGGsfRQzSadPkqVNlyVmyYRQVsr6eNteXf+uhXJ7JeTHpd8lVWsEwjho9WHqpb+ptV8/YRBJe0Y/jtXpRSNlD0MdQ7PGPe1uvOPJL1VPyY4YVbfRyudZ6+lBfara8cLk2+FzB6nPamf27TBMmiQsfCKH0sQVDsceres0drrKfJErkeDBZgtLX1+ne9/uOu4pic+epwhFnVHP2yMCFE4NLNySqE4Scibn1EYP07m1tBcviMqYrwhdkVHP1jO2ravOKZwyyGI46yHGvpN2efTtNOQXKH447AMDkPEXWbOX+XR0MzVG3OPR9fahfpRXMWKAOa3hjgJkL1XIV//Th/sDJAukbNFNX6mwlaxPCHdvYYMG6hH+ettoG6ABpAuk78Yl5xgK1QIhFILYxgFDMmz4vtuaT3gBp/OobNFPmTlf2XGVkYhsb5BSoultdASqgX33f1Nuz5yqxsfEYFil4OMieq/ym3uY3gb8dTedtk6YM5zEQhqKioq6urlBz7d69e+vWrZGJCEyaIm1qsPvb61uf3UI7bYxGx91uDCPt7e12u99AA9DY2BiBcL5FqxdZ+2l/56/vDqvOG2SoD8/Bw7JsZWXlwYMHW1tb09LSZs2atWHDhrNnz27cuBEAUFZWVlRUtG3btqampo8++qiurq6rqystLe2BBx5YunQpAODatWtr1qx56623Xnnllfj4eIlEUl9fDwDYt2/fBx98kJGREfaA4/WinjaXItaHK9/6XAQjUcB2BfqjsrLy/fffX79+fVpamslk+t3vfqdUKteuXfvmm2/+7Gc/q66uTkhIAABs3769u7v7+eefxzCsubm5oqLCYDDk5uYKhUIAwDvvvPPII49MmzYtMzPzoYceSk9P37JlS4QClihwl4PxucuPPqdHGtwz8zBoaGiYOnXq2rVrvb/m5eW53e7vJ3vjjTccDodOp/OmqaqqOnnyZG5urnfvnDlzVq9eHaEIb0Mix11Oj89dvvV5PCwuiFRzLzs7e8eOHRUVFUajsaCgwGAw+InBU1lZ+dVXX928edO7JTMzc2jvlClTIhTe9xEIef6e3nzrk8hwc6ePGhEW1q1bp1Aojh49umXLFj6fv2jRoqeeeio2NvbWNAzDbNq0iWXZTZs2zZw5UyaTrVu3zrsLwzAAgFgM1ckeEg4bHT/R9+F865Mq+I5rjghFg+N4eXl5eXl5c3Pz6dOnd+7cSZLk66+/fmuaxsbGK1eu7Ny502g0ercM3ZRH/q0Sh5WRKnxfyvzUPgXutPm+WMJTXV2dlZWVkpKSlpaWlpbW19d35MiRoWrlxWazAQC02m+7Zq9evdre3j504buNWzNGAsJGS2N8i/Ld7tMmicwdLg8Tkf9zdXX1s88+W1NTY7Vaa2pqjh8/npOTAwDQ6/UAgM8///zy5cupqakYhlVWVtrt9paWlrfeeis/P7+zs9NngUlJSZcuXTpz5szAwEDYo6Up1tJD+W0Cs374dEdH8wW7v70wdHZ2PvPMM0aj0Wg0Lly4cNeuXU6n07vrxRdfzM/P37BhA8uyhw4dWr58udFoLC8vb2xs/OKLL4xG4+rVq69fv240Guvq6oYKrKurW7Zs2cyZM0+fPh32aJsabPt3dfjb67e3+dLJQVMLueDBCWH/f44tDv+5a2KGNHOW76Exv8+8GUZF2zVH4N6ucY9tgG7/xnmH/572QGMd549bTC3kovW+u0s7OjqGmr63wePxPB7f7cwVK1Y88cQTQUQ+HJ5++umGhgafu1QqlcVi8bnr1VdfnTt3rs9dB9/r1N8hzSnw22sXSJ+HAX997cbcpdq0HB9dLx6PhyAInxlJkvTXLhMIBJFrsjkcDobx3WCgKEog8D2iL5FI+HwfN9ZrZ221B/seejE5UK9d4AtnTxu564Xm/i532C/JUY7Z5Nr1QnNPGxk4GUd3qFYvWrAu4cC7Jjfp+2Qcl7hJz4F3TIvW6zi7nYIaJr961tbwpaXssUSZMlL9CNGD3UIfeLczd54qmLHZYF/S6Gh2Ht3Ts2BdQrwhUv2A0UDPTdfhv3SVrJmgSwnqAh3CK0LWfnr/ro6ULPnMhWr+uBt+o9zs15/1tV113PdYYow62L7O0F5QYyi28Wvr1bO2qXOUaTlygWg8SKRcnqbz9su11sz8GH/NY38M8/XIlkvE9YuE3UJpdCK5ii+W4WIZPlZGhCk3SxIMSTB2C23udCliBanZspSReT3yNjqvk/1d7kEzZel1k44w3537+voAABqNJrzFimU8VZxQqRVoEoQJyaPxcu7IsHPnTgzDHn/88dEOxC8/7GFwaJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KJA+KKLxs5j77ruPYRiWZZ1OJwBAJpMxDCMQCA4cODDaod1OpKZJg0Gn09XX1w9NbuP9xD4vL2+04/JBNJ68q1atUqm+Mz25RqMZmsMqqohGfSUlJenp6bduSU5OLiwsHL2I/BKN+rzzlSiV307/oVKp1qxZM9oR+SZK9RUXFycnJ3t/njRp0vz580c7It9EqT4AwMqVK2UymUwmW7ly5WjH4pfQ7ry0m+1td3k8I9HWyUotmJI8F8fxrNSCjibnCByRx8O0elFI0zQE2+7raXMd29tLWGmZko+BsfHRfaiwgCUstFzFL1qujUsKasKQoPRdqrWePtQ/f7VOoxvPs5B4MZtcR3ebZi3SBDMtBPe1z2xy11abSx/V/xDcAQDiEkWlj+hP7jf3d3HP3sqt7+Q+87RCjUIVjc8nEUIRK5hWqDm5v48zJbe+7lYyNVsepsDGDClT5Z0t3PcrDn2kw4PxgEg6/qeuug2xDMcw4G+26yG4ah/Ljs+7bDBggOWamCZ6m81jAqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPiujV99KWzc/+509HOwoORlnf4qVF3d2+V1UsLCwpnl864hGFxmh2gnaYAq2qWFIc7e4iUvv27v1wxap7jx3/+/ySGW/veBMAYDb3bq14fuXq++4vL3ntjS0dpnYAwLn6unUP3g8AWLWm7KUtmwEAS5bO+7hqz0+fenRecZ7D4bj15PVZAkEQ9yyc9cGHfxo6NEVRpffOff/Pf/CXJeyEX59AKCQI+4EDVT9/8dUlS5bTNP3M5g2XGy/8x+Ytf3z3f+VyxRNPPtzd3TU9d8Zrv3wTALD7g+qKrdsAAEKRaH/13qzMnG2/elsk+te4ir8SZDLZrPy7a04cHUpZV1frcrmKi0v9ZQn7HxuRa5/D4Vi75tH58xbokyaev3Cura31hecq8oz5sbHqJzc+I5FI9n78oc+MsSr1xg1PG6fPxPF/9W8HKKGwsOTKlct9fWZvypoTR++cnBnqQWGI1K3jzjuzvD9cvnxBLBZPmzbd+yuO41On3nXxku8lcSZPzvz+xgAl3D23SCQSHTt2xLuw4Mmvjs2btyDUg8IQ/luH9728obOPIOwkSc4r/s7beQkTdD7zelc/vY0AJYjFYu/5W16+6vyFczabtaR4UagHhSH8+m4bd9do4mQyWcXW7d85Kh7CcQOXUFR0T8UvXxi0Dp44cTT3rjy1WhOWgwZJxBsuKSnpBEFMmKBL1CV5t3SY2jXquOAXRwxQAgBg9qwCkUhUW3v87/84/JPHfhpMljAS8WbzjLxZM/Jmbd/+y56ebotlYO/HuzdsWPfFkYMAgMREPQDg6Jef//PK5eGV4L1KzJ5VUFW1x+EgCgrmB5MljIxEs/mN13+zb//eVyqea2y8aDAk33vv/YvLygEABkNycXHpu++9nZOdu33bjmGU4KWwsOTlXzw7e3aBMkYZZJZwwfGKEEkwf32tdeWzqWE/cPSz+79aHnwhWSwLdIJGb5fBmADpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpg4JLH4ZF3VQHIwjGpYdjv1jKY2iWcv/gHLpID+sBIgmHH+6TN36i2NTsCF9gY4OuFke8nvsbPm59effEnqrusQ3QYQpsDGAboE8d6MlboOZMGdQHqRdPDJ460Dd9QVzqVMX4W9T9Vmg323LRdvYL85zFcVPncH+QGtrn0OYOlyZRxOONkEEPywIAeMENyIXhcB62z+SKnygqfCCsn0MPQbvZnnYXOyIf4wMA9u/fDwBYvHjxyBxuGB/jhzbSxhdiialQa6GHBCYdwDAsKV0yYkcMFdRshgLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgwLpgyIa1yYvKyszmUwsyw7Nj8iybGJiYhSuTR6Nta+srAzHcRzHef8Pn89fsmTJaMflg2jUt2LFCr1ef+sWg8GwatWq0YvIL9GoT61Wl5aWDp25GIaVlJQMrbUdVUSjPgDA8uXLJ06c6P1Zr9evXr16tCPyTZTq02g0JSUlGIZhGFZaWqpSqUY7It9EqT7v2uQGgyEpKSma1yYPQ8OFGKSbztsH+2injSEJxuUKW0uot6cXYECr1YarQJEIE8twqQKP0fDTp8llStiJg4evj6HYc0ct1+pt1j5KpZPxRQJciPMFOM6P3hrN0B6aYhiKoR2UpZuI0QinzJBPK1DhgmF+7z9MfdfO2WuqegUyYawuRhEvHd6xRx1rj8PSaaUId8Eybcb04SzhHLI+l9NT/YeuQQuTkK6Wxo7ch/mRg+h3djcNKNX4ksd1AlFo1TA0fdZ+uup/OmRaRVxyNLbCYOi9bnEOEPdvTIxRh3BBDEFf903y4Hvd2gyNPDZ652aAwd5H9jSZFz+WoA1i/iAvwV7mHVbmwHvdiVnx49UdAECuESdmxVe/20VYmSCzBKWPptiqtzvi0zQiuY/lSMYTYrlQm6b59Pcmhg7qpAxK36mD/VK1XB43buvdrcg1ErFS+vWh/mASc+sjBpkbjY7YiePtXhEAtUHVfMFBDHLPesat79jHvcqkKH3kjBzKRGXNp32cyTj0kYSnvcmp0EZpw3jA0rX5pfzGKyfCXnJMvKy1kSAJjnsIh76m87YYrSysgY0RMBAzQdZyye8akF449H3TQMjiorTqRRq5WtrUwDFtJkcLu7eNTJsTtg6P2xi09u777NetbRcpynXnHbPvmfdYnEYPAKip3XO05i//vv637+9+rqf3hi7hjnl3Pzh92kJvrnMXDh8+spN0EZl3Ftyd/2MAAIjMBH8SlejGaXPgNIFqH02xNM1GqAeFYejf//HJ1raLK+7/+eZNH0okit/senTA0gUA4POFTtL6ycHtK5f9/FdbT2VNLthTtdVm7wcAdHY3ffjRy/l5S597+qPc7AWfHPzvSMTmhS/EKcrj8QRKE0jNoJmSyAXhjwsAAEDLjfpec+vqB36RkT5TIVcvLn1aJJTU1O7xDm5QlKu0eMOkidkYhhnvWsQwdIfpKgDgxKm/qWOT5v/oYYlEkZE+c+b0yM6MKJbyB81UgASB9NktNF+EB0gAw42bF4QCcVrKv5aRTDZMu3Hz/NA6gwb9t6tcisVyAADpsgMA+vrbJ8SnDBWiT5oCAIjc3JwCCd9uCdT6C3Tt4wuxyI2hky7CTZGbX8q/dWOsSgcAACz7/TUEvU6dTptcFju0UcAXfX9ZxzDCMCwesP4E0ieV44wrUvMNK+QasUi2fs2vbt3ICxwsAGKx3E2RQ7+6KWfwizUOA9rFSGMC1rAA+yQKvpsMtu8hVHQJ6aSLiFUlaNTfLiNp7m+PkXMsIxmrSrjW9PXQ+xtXrn0V0dpHOWmpItB/NNC1Tyzl8YU8ioxIBZycnp+Rnv+3T1+zDHbbiYGa2j2/3vHw2fOfBc6Vk1VstZmrD/8WAPBNc92pM5+AiDVc3A5aIMaF4kCKONp9hjultl6HeiL3BNDD4LEHf11b9/Ff9rzY2nYxXpucb1w6e8aywFkyJ8+9d8GTp+qqjp2sjFXpVpVv2fHeRo8nIqeIzexImcrxxMXR29x83l57aFCfkxDu2MYA7ee75pSpUgMa5GgS6zOkgz1Ot+MHNGG9F7eTtvY6J2ZwPLBynLwiCW+yMaarZUA/1fejG8PQL7+x0OcumnbzcaHPVlmSLmPjo4FWlA2Vl14tYYHv08jjYXg8H5d/gz7r8Yd/46/Anqb+yTNiBFwziHMPFTntzPsVN5LzEsV+eur7B0w+t5Ok3dvi/T44LlDGhPNR2l8MAAA35RIKfAz98PnCGIXvGz1pc7ee61z/cjLneh1BjbTVfzlw7qg1ZUYiD4/eNwjChYf2XK8zzbhHmVPA3UkclI67fqTSJgraL/VG4Zu84YVl2bYL3XGJguy5QQ1OBKUP42H3PqoT4EzX1aAGUMYunVf6hUL2vn/TYcEtqhHsycgXYMueSAS062ZDtye4QbyxhYdmbzZ0Yx73sieS+EG/MRTaSxoMzX72p67um25DboJAPBLLwo8MFEm3nutKTBUtfHACzg/hGWY4b1id+XzgzD8G4gxKtUHJw8f22jsMw/a3WvpuWvPuic0riQ0ix3cY5gtqA91U/THL9UuEVCWVqERyjYQvjFTPYCSgScY+4HQMupwDjtRsWW6RSqUdTscw1NulNMXeuOy41kC0/dPOAkwsFwilAr4oSk9qlgWMm3Y7KJJwYywwZMrvyJWl50CNI4btqyK7hbb0UoNmKpjB+dEBA7IYvjJOoNIK5Krw/I+j8aOsMcT4f4qIKEgfFEgfFEgfFEgfFEgfFP8Hsf5FPke2zr4AAAAASUVORK5CYII=",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x113a38e90>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: list[Document]  # From retrieval node\n",
    "    internet_context: list[Document]   # From search if needed\n",
    "    evaluation_result: str             # Decision from evaluator\n",
    "    response: str  \n",
    "\n",
    "def retrieve(state: State) -> State:\n",
    "    retrieved_docs = compression_retriever.invoke(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder = graph_builder.add_sequence([retrieve])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "retrieval_graph = graph_builder.compile()\n",
    "\n",
    "retrieval_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b3b00b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the front facing height and weight limits for the car seat?',\n",
       " 'context': [Document(metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign CC 2017 (Windows)', 'creationdate': '2024-02-27T10:43:44-05:00', 'moddate': '2024-02-28T00:09:55-05:00', 'trapped': '/False', 'source': './data/foonf_2024_manual_US_EN_02_27_2024_WEB_Final.pdf', 'total_pages': 100, 'page': 17, 'page_label': '15', '_id': '70b5ad69b53c447f81a3900f24f5d1b9', '_collection_name': 'Manuals', 'relevance_score': 0.75312227}, page_content='15\\n  When Using This Car Seat \\nin Forward-Facing Mode\\nP Child’s weight is between 22 and 65 lb \\n(10 and 29.5 kg).\\nP Child’s height is between 30 and 49 in. \\n(76 and 124 cm).\\nP Child is at least 1 year of age.\\nP Car seat is securely installed in a rear \\nvehicle seating position using either the \\nrigid LATCH Connectors and the Top \\nTether; the vehicle belt and Top Tether; or \\nthe rigid LATCH Connectors, the vehicle \\nbelt, and the Top Tether.\\nNOTE: If child weighs more than 35 lb \\n(15.9 kg), this car seat must be installed \\neither with the vehicle belt and the Top \\nTether or with the rigid LATCH lower \\nconnectors, the vehicle belt, and the \\nTop Tether. \\nP Car Seat is properly assembled with  \\nthe headrest properly secured. The  \\nRear-Facing Base and Anti-Rebound  \\nBar must be removed when using seat \\nForward-Facing.'),\n",
       "  Document(metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign CC 2017 (Windows)', 'creationdate': '2024-02-27T10:43:44-05:00', 'moddate': '2024-02-28T00:09:55-05:00', 'trapped': '/False', 'source': './data/foonf_2024_manual_US_EN_02_27_2024_WEB_Final.pdf', 'total_pages': 100, 'page': 6, 'page_label': '4', '_id': '17b59d14c7f54640b52e9ac15778f270', '_collection_name': 'Manuals', 'relevance_score': 0.7373288}, page_content='on product labels and in this\\nmanual and in your vehicle\\nowner’s manual before installing\\nor using this car seat.\\n• Failure to properly install or use\\nthis car seat or follow these\\nwarnings and those on this car\\nseat’s labels can result in serious\\ninjury or death to the child\\nin a sharp turn, sudden stop or\\ncrash.\\nC01-0602-G1-US\\nFoonf Instruction Manual\\nThis car seat is designed for use either Rear-Facing or Forward-Facing by children who meet\\nall of the following requirements:\\nHEIGHT WEIGHT AGE\\n25 – 43 in.\\n64 – 110 cm\\n14–5 0l b\\n6.4 – 22.7 kg\\nAble to sit\\nupright alone\\nHEIGHT WEIGHT AGE\\n30 – 49 in.\\n76–1 24 cm\\n22 – 65 lb\\n10–2 9.5 kg\\n2+ years\\nrecommended\\n(1 year min.)\\nFebruary 2024\\nFO24USG1\\n39\\n38\\n36'),\n",
       "  Document(metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign CC 2017 (Windows)', 'creationdate': '2024-02-27T10:43:44-05:00', 'moddate': '2024-02-28T00:09:55-05:00', 'trapped': '/False', 'source': './data/foonf_2024_manual_US_EN_02_27_2024_WEB_Final.pdf', 'total_pages': 100, 'page': 0, 'page_label': 'COV1', '_id': '3034915d98794fe984dcea0a73573132', '_collection_name': 'Manuals', 'relevance_score': 0.73322314}, page_content='WARNING\\n• Read and understand all \\ninformation and instructions \\non product labels and in this \\nmanual and in your vehicle \\nowner’s manual before installing \\nor using this car seat.\\n• Failure to properly install or \\nuse this car seat or follow these \\nwarnings and those on this car \\nseat’s labels can result in serious \\ninjury or death to the child \\nin a sharp turn, sudden stop \\nor crash.\\nC01-0602-G1-US\\nFoonf Instruction Manual\\nThis car seat is designed for use either Rear-Facing or Forward-Facing by children who meet \\nall of the following requirements:\\nHEIGHT WEIGHT AGE\\n25 – 43 in.\\n64 – 110 cm\\n14 – 50 lb\\n6.4 – 22.7 kg\\nAble to sit \\nupright alone\\nHEIGHT WEIGHT AGE\\n30 – 49 in.\\n76 – 124 cm\\n22 – 65 lb\\n10 – 29.5 kg\\n2+ years \\nrecommended  \\n(1 year min.)\\nFebruary 2024\\nFO24USG1FO24USG1')]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_graph.invoke({\"question\" : \"What are the front facing height and weight limits for the car seat?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f109885",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "Now I am going to create helper functions to help me quickly build the nodes, the graph and the connections between them.We will have our helper accepts the following parameters:\n",
    "\n",
    "\n",
    "- llm: the llm that will power this agent node\n",
    "- tools: the list of tools available to the llm\n",
    "- system_prompt: the system prompt to attach to the llm to ground its generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e3fba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, List, Optional, TypedDict, Union\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cd0e4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    \n",
    "    # Extract the actual output text from the agent result\n",
    "    if isinstance(result, dict):\n",
    "        output_text = result.get('output', str(result))\n",
    "    else:\n",
    "        output_text = str(result)\n",
    "    \n",
    "    # Return two messages: one identifying the agent, one with its response\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=f\"{name} agent responding:\"),\n",
    "            AIMessage(content=output_text, name=name)\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d295adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(\n",
    "    llm: ChatOpenAI,\n",
    "    tools: list,\n",
    "    system_prompt: str,\n",
    ") -> str:\n",
    "    \"\"\"Create a function-calling agent and add it to the graph.\"\"\"\n",
    "    system_prompt += (\"\\nWork autonomously according to your specialty, using the tools available to you.\"\n",
    "    \" Do not ask for clarification.\"\n",
    "    \" Your other team members (and other teams) will collaborate with you with their own specialties.\"\n",
    "    \" You are chosen for a reason!\")\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "248ff377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_router(llm: ChatOpenAI, system_prompt, members) -> str:\n",
    "    \"\"\"An LLM-based router.\"\"\"\n",
    "    options = [\"FINISH\"] + members\n",
    "    \n",
    "    tool_def = {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"route\",\n",
    "            \"description\": \"Select the next role.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"next\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": options,\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"next\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\n",
    "                \"system\",\n",
    "                \"Given the conversation above, who should act next?\"\n",
    "                \" Or should we FINISH? Select one of: {options}\",\n",
    "            ),\n",
    "        ]\n",
    "    ).partial(options=str(options), team_members=\", \".join(members))\n",
    "    \n",
    "    \n",
    "    return (\n",
    "        prompt\n",
    "        | llm.bind_tools([tool_def], tool_choice={\"type\": \"function\", \"function\": {\"name\": \"route\"}})\n",
    "        | JsonOutputFunctionsParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2833045",
   "metadata": {},
   "source": [
    "### Create the tools\n",
    "For this application we need only tavily.\n",
    "\n",
    "Tavily search for which we can just pull the implemented API from the library. \n",
    "\n",
    "If we were to create a custom tool we would just need to define  a function that calls the node and add the tool decorator. There is an example below, however we are not going to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c3445ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/hq4dj_jn0l96rctpr1_nhgyr0000gn/T/ipykernel_53464/3644306814.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_tool = TavilySearchResults(max_results=5)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "tool_belt = [\n",
    "    tavily_tool,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "617ce90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Tuple, Union\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def retrieve_information(query: Annotated[str, \"Query to ask the retrieve information tool\"]):\n",
    "    \"\"\"Use Retrieval to retrieve information about the user query\"\"\"\n",
    "    return retrieval_graph.invoke({\"question\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61841078",
   "metadata": {},
   "source": [
    "### Let's define the state functions\n",
    "\n",
    "First let's define what we want to keep track of at every step of the execution.\n",
    "\n",
    "- messages: The messages we've passed so far\n",
    "- team_members: which team members we have access to\n",
    "- next: what team member is up next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39be9f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "import functools\n",
    "\n",
    "class RetrievalState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    team_members: List[str]\n",
    "    next: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b62698b",
   "metadata": {},
   "source": [
    "### Now it is time to define the orchestrator node, the router in this case\n",
    "\n",
    "The router will receive the context from the retrieval and then decide whether it should call tavily or pass the context directly to the writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c7d9007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143a747f",
   "metadata": {},
   "source": [
    "### It is finally time to define the agents\n",
    "As a recap, we need:\n",
    "- a retrieval node, which we already have\n",
    "- a router/orchestrator agent that can either call the search or writer agent\n",
    "- a search agent\n",
    "- a writer agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent = create_agent(\n",
    "    llm, \n",
    "    tool_belt, \n",
    "    \"You are a research assistant who can search for details to asnwer the user query.\"\n",
    "    )\n",
    "\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "106f6b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_agent = create_agent(\n",
    "    llm, \n",
    "    [], \n",
    "    \"You are a writer. Use the provided context to answer the user's question clearly and accurately.\"\n",
    ")\n",
    "\n",
    "def writer_node(state, agent, name):\n",
    "    # Combine retrieved context + any internet search results\n",
    "    combined_context = state.get(\"retrieved_context\", []) + state.get(\"internet_context\", [])\n",
    "\n",
    "        # Pass the combined context to the agent\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=f\"Question: {state['question']}\\nContext: {combined_context}\")\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    return {\"response\": result}\n",
    "\n",
    "writer_node = functools.partial(writer_node, agent=writer_agent, name=\"Writer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca11acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1729ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_agent = create_router(\n",
    "    llm,\n",
    "    (\"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  Search, Writer. Given the following user request,\"\n",
    "    \" determine if the information is enough to answer the user query. If it is,\"\n",
    "    \" pass the context to Writer. If it is not, pass the query to Search.\"\n",
    "    \" You should never ask Search to do anything beyond research.\"\n",
    "    \" You should never ask Writer to do anything beyond writing the answer given\"\n",
    "    \" the retrieved and searched context.\"\n",
    "    \" When finished, respond with FINISH.\"),\n",
    "    [\"Search\", \"Writer\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57581a87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ManualAIze (uv)",
   "language": "python",
   "name": "manualaize"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
